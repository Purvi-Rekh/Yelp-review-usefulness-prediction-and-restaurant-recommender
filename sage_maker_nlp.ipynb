{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from sagemaker.tensorflow import TensorFlow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3=boto3.resource(\"s3\")\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.manifold import TSNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = pd.read_csv(\"new_dataset_indian_resto_review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_useful(df):\n",
    "#     if (df[\"useful\"] == 0) & (df[\"funny\"] == 0) & (df[\"cool\"] == 0):\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return 1\n",
    "    \n",
    "    #print(df[4],df[7],df[8])\n",
    "    if df[4] == 0 and df[7]==0 and df[8] ==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "        \n",
    "#         return df[4]\n",
    "#     else:\n",
    "#         return 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "review[\"label\"] = review.apply(find_useful,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>useful</th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>iE71iwcSljg3xm2GB2Y9aA</td>\n",
       "      <td>Marigold Maison- Paradise Valley</td>\n",
       "      <td>Indian, Restaurants</td>\n",
       "      <td>0</td>\n",
       "      <td>I have been here several times since my last u...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DJuQgsoj-qmU0i5iTAa4aA</td>\n",
       "      <td>Tadka Restaurant</td>\n",
       "      <td>Restaurants, Indian</td>\n",
       "      <td>0</td>\n",
       "      <td>We just tried to eat here and I'm pretty sure ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             business_id                              name  \\\n",
       "0           0  iE71iwcSljg3xm2GB2Y9aA  Marigold Maison- Paradise Valley   \n",
       "1           1  DJuQgsoj-qmU0i5iTAa4aA                  Tadka Restaurant   \n",
       "\n",
       "            categories  useful  \\\n",
       "0  Indian, Restaurants       0   \n",
       "1  Restaurants, Indian       0   \n",
       "\n",
       "                                                text  stars  funny  cool  \\\n",
       "0  I have been here several times since my last u...    5.0      0     0   \n",
       "1  We just tried to eat here and I'm pretty sure ...    1.0      1     0   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = review[[\"text\",\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    43195\n",
       "0    36597\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = review.dropna()\n",
    "review.head(5)\n",
    "review[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>normalizes_text</th>\n",
       "      <th>remove_special</th>\n",
       "      <th>token_text</th>\n",
       "      <th>remove_stop</th>\n",
       "      <th>lemitize_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have been here several times since my last u...</td>\n",
       "      <td>0</td>\n",
       "      <td>I have been here several times since my last u...</td>\n",
       "      <td>I have been here several times since my last u...</td>\n",
       "      <td>[i, have, been, here, several, times, since, m...</td>\n",
       "      <td>[several, times, since, last, update, , , food...</td>\n",
       "      <td>several time since last update   food always t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We just tried to eat here and I'm pretty sure ...</td>\n",
       "      <td>1</td>\n",
       "      <td>We just tried to eat here and I'm pretty sure ...</td>\n",
       "      <td>We just tried to eat here and Im pretty sure i...</td>\n",
       "      <td>[we, just, tried, to, eat, here, and, im, pret...</td>\n",
       "      <td>[tried, eat, im, pretty, sure, closed, , table...</td>\n",
       "      <td>tried eat im pretty sure closed  table pushed ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  I have been here several times since my last u...      0   \n",
       "1  We just tried to eat here and I'm pretty sure ...      1   \n",
       "\n",
       "                                     normalizes_text  \\\n",
       "0  I have been here several times since my last u...   \n",
       "1  We just tried to eat here and I'm pretty sure ...   \n",
       "\n",
       "                                      remove_special  \\\n",
       "0  I have been here several times since my last u...   \n",
       "1  We just tried to eat here and Im pretty sure i...   \n",
       "\n",
       "                                          token_text  \\\n",
       "0  [i, have, been, here, several, times, since, m...   \n",
       "1  [we, just, tried, to, eat, here, and, im, pret...   \n",
       "\n",
       "                                         remove_stop  \\\n",
       "0  [several, times, since, last, update, , , food...   \n",
       "1  [tried, eat, im, pretty, sure, closed, , table...   \n",
       "\n",
       "                                       lemitize_text  \n",
       "0  several time since last update   food always t...  \n",
       "1  tried eat im pretty sure closed  table pushed ...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accents(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
    "    return only_ascii.decode()\n",
    "stopwords_ = set(stopwords.words(\"english\"))\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(india_review):\n",
    "    india_review[\"normalizes_text\"] = india_review[\"text\"].apply(lambda x:remove_accents(x))\n",
    "    #india_review[\"remove_html\"] = india_review['normalizes_text'].apply(lambda x: strip_html_tags(x))\n",
    "    india_review[\"remove_special\"] = india_review[\"normalizes_text\"].replace(r'[^A-Za-z0-9 ]+', '', regex=True)\n",
    "    \n",
    "    india_review[\"token_text\"] = india_review[\"remove_special\"].apply(lambda x:[word.lower() for word in x.split(\" \")]) \n",
    "    #india_review[\"token_text\"] = india_review[\"token_text\"].apply(lambda x:[word for word in x if word not in common_words_list])\n",
    "    \n",
    "    india_review[\"remove_stop\"] = india_review[\"token_text\"].apply(lambda x:[word for word in x if word not  in stopwords_])\n",
    "    india_review[\"lemitize_text\"] = india_review[\"remove_stop\"].apply(lambda x: \" \".join([lemmatizer.lemmatize(word) for word in x]))\n",
    " #   india_review[\"length\"] = india_review[\"remove_stop\"].apply(lambda x:find_length(x))\n",
    "   # review[\"clean_list\"] = review[\"lemitize_text\"].apply(lambda x:[word for word in x.split(\" \")])\n",
    "#    india_review[\"texts_to_sequences\"] = india_review[\"lemitize_text\"].apply(lambda x:)\n",
    "\n",
    "    return india_review\n",
    "     \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "review=pre_processing(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#review[\"lemitize_text\"]\n",
    "train_set = review.sample(frac=0.75, random_state=0)\n",
    "test_set = review.drop(train_set.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_review = train_set[\"lemitize_text\"]\n",
    "test_review = test_set[\"lemitize_text\"]\n",
    "train_review.head()\n",
    "label_train = train_set[\"label\"]\n",
    "label_test = test_set[\"label\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42791    went lunch service ok napkin paper towel bathr...\n",
       "33833    came excellent yelp review let say yelp commun...\n",
       "40033    place attached holiday inn let fool food amazi...\n",
       "36423    making visit namaste never tried indian partic...\n",
       "28831    place delicious dinner family 7 staff friendly...\n",
       "Name: lemitize_text, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_review.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_sequn(review):\n",
    "    max_len=50\n",
    "    embed_dim=100\n",
    "    max_words=20000\n",
    "    tokenizer = Tokenizer(num_words=max_words,char_level=True)\n",
    "    tokenizer.fit_on_texts(review[\"lemitize_text\"])\n",
    "    sequences = tokenizer.texts_to_sequences(review[\"lemitize_text\"])\n",
    "    data = pad_sequences(sequences,maxlen=max_len,padding='post')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.asarray(review[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
